{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"CELL 1: CLONING GITHUB REPOSITORY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "repo_url = \"https://github.com/aravinds-kannappan/nfl-veteran-transition.git\"\n",
        "repo_name = \"nfl-veteran-transition\"\n",
        "\n",
        "print(f\"\\n▶ Cloning repository: {repo_url}\\n\")\n",
        "\n",
        "if not os.path.exists(repo_name):\n",
        "    result = subprocess.run(\n",
        "        [\"git\", \"clone\", repo_url],\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    if result.returncode == 0:\n",
        "        print(\"✓ Repository cloned successfully\")\n",
        "    else:\n",
        "        print(f\"✗ Error: {result.stderr}\")\n",
        "else:\n",
        "    print(f\"✓ Repository already exists\")\n",
        "\n",
        "# Change directory\n",
        "os.chdir(repo_name)\n",
        "print(f\"✓ Working directory: {os.getcwd()}\\n\")\n",
        "\n",
        "# Create output directories\n",
        "output_dirs = [\"outputs\", \"outputs/models\", \"outputs/analysis\", \"outputs/figures\"]\n",
        "for dir_path in output_dirs:\n",
        "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"✓ Output directories created\")\n",
        "print(\"\\n✓ CELL 1 COMPLETE\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8YevqOgZwlL",
        "outputId": "57500570-0ce1-4f2d-85c4-150258f372bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CELL 1: CLONING GITHUB REPOSITORY\n",
            "================================================================================\n",
            "\n",
            "▶ Cloning repository: https://github.com/aravinds-kannappan/nfl-veteran-transition.git\n",
            "\n",
            "✓ Repository cloned successfully\n",
            "✓ Working directory: /content/nfl-veteran-transition\n",
            "\n",
            "✓ Output directories created\n",
            "\n",
            "✓ CELL 1 COMPLETE\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"CELL 2: INSTALLING DEPENDENCIES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "packages = [\n",
        "    \"pandas\",\n",
        "    \"numpy\",\n",
        "    \"scikit-learn\",\n",
        "    \"matplotlib\",\n",
        "    \"seaborn\",\n",
        "    \"xgboost\",\n",
        "    \"lightgbm\"\n",
        "]\n",
        "\n",
        "print(\"\\n▶ Installing required packages...\\n\")\n",
        "\n",
        "for package in packages:\n",
        "    try:\n",
        "        __import__(package.replace(\"-\", \"_\"))\n",
        "        print(f\"✓ {package} already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"  Installing {package}...\")\n",
        "        subprocess.run(\n",
        "            [\"pip\", \"install\", \"-q\", package],\n",
        "            capture_output=True\n",
        "        )\n",
        "        print(f\"✓ {package} installed\")\n",
        "\n",
        "print(\"\\n✓ CELL 2 COMPLETE\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8UumkEFem8l",
        "outputId": "cca717c5-8baf-4523-cf7d-4cd0a494fcd4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CELL 2: INSTALLING DEPENDENCIES\n",
            "================================================================================\n",
            "\n",
            "▶ Installing required packages...\n",
            "\n",
            "✓ pandas already installed\n",
            "✓ numpy already installed\n",
            "  Installing scikit-learn...\n",
            "✓ scikit-learn installed\n",
            "✓ matplotlib already installed\n",
            "✓ seaborn already installed\n",
            "✓ xgboost already installed\n",
            "✓ lightgbm already installed\n",
            "\n",
            "✓ CELL 2 COMPLETE\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"CELL 3: VERIFYING DATA & SETUP\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "csv_path = \"data/processed/nfl_panel_for_python.csv\"\n",
        "\n",
        "print(f\"\\n▶ Loading data from: {csv_path}\\n\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"✓ Data loaded successfully\")\n",
        "    print(f\"  • Rows: {len(df):,}\")\n",
        "    print(f\"  • Columns: {len(df.columns)}\")\n",
        "    print(f\"  • Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    print(f\"  • Missing values: {df.isnull().sum().sum()}\")\n",
        "    print(f\"  • Duplicates: {df.duplicated().sum()}\")\n",
        "\n",
        "    print(f\"\\n✓ Sample data:\")\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error: {e}\")\n",
        "\n",
        "# Verify scripts exist\n",
        "print(f\"\\n▶ Verifying Python scripts:\\n\")\n",
        "\n",
        "scripts = [\n",
        "    \"src/python/data_collection.py\",\n",
        "    \"src/python/preprocessing.py\",\n",
        "    \"src/python/feature_engineering.py\",\n",
        "    \"src/python/modeling.py\",\n",
        "    \"src/python/main.py\"\n",
        "]\n",
        "\n",
        "all_exist = True\n",
        "for script in scripts:\n",
        "    if os.path.exists(script):\n",
        "        print(f\"✓ {script}\")\n",
        "    else:\n",
        "        print(f\"✗ {script} NOT FOUND\")\n",
        "        all_exist = False\n",
        "\n",
        "if all_exist:\n",
        "    print(\"\\n✓ All scripts found!\")\n",
        "else:\n",
        "    print(\"\\n✗ Some scripts missing!\")\n",
        "\n",
        "print(\"\\n✓ CELL 3 COMPLETE\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ1SesHFeqtv",
        "outputId": "0c54d05b-687c-44c6-99ef-5a706dc8cda0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CELL 3: VERIFYING DATA & SETUP\n",
            "================================================================================\n",
            "\n",
            "▶ Loading data from: data/processed/nfl_panel_for_python.csv\n",
            "\n",
            "✓ Data loaded successfully\n",
            "  • Rows: 599\n",
            "  • Columns: 28\n",
            "  • Memory: 0.28 MB\n",
            "  • Missing values: 1170\n",
            "  • Duplicates: 0\n",
            "\n",
            "✓ Sample data:\n",
            "      gsis_id  season  metric_raw  volume  success_rate  total_epa team  \\\n",
            "0  00-0019596    2019    0.021802     642           NaN        NaN   NE   \n",
            "1  00-0019596    2021    0.184091     742           NaN        NaN   TB   \n",
            "2  00-0019596    2022    0.054289     761           NaN        NaN   TB   \n",
            "3  00-0021206    2015    0.011931     319           NaN        NaN  CLE   \n",
            "4  00-0021206    2017    0.010371     437           NaN        NaN  NYJ   \n",
            "\n",
            "  position_group  metric_secondary  mean_season  ...  new_team  rel_time  \\\n",
            "0             QB          0.419003     0.050641  ...        TB        -2   \n",
            "1             QB          0.506739     0.014965  ...        TB         0   \n",
            "2             QB          0.473062     0.004703  ...        TB         1   \n",
            "3             QB          0.432602     0.029473  ...       NYJ        -2   \n",
            "4             QB          0.441648    -0.004887  ...       NYJ         0   \n",
            "\n",
            "   post_transition  phase team_pos_avg  team_quality  team_pass_epa_per_play  \\\n",
            "0                0    Pre    -0.239498     -0.043077                0.017513   \n",
            "1                1   Post     1.347871     -0.030464                0.180297   \n",
            "2                1   Post     0.427404     -0.028241                0.040399   \n",
            "3                0    Pre    -0.564348     -0.079580               -0.081337   \n",
            "4                1   Post     0.114395     -0.084079               -0.051446   \n",
            "\n",
            "   team_rush_epa_per_play team_sack_rate  pre_trend_slope  \n",
            "0               -0.066716       0.043077              0.0  \n",
            "1               -0.006274       0.030464              0.0  \n",
            "2               -0.220192       0.028241              0.0  \n",
            "3               -0.103147       0.079580              0.0  \n",
            "4               -0.106556       0.084079              0.0  \n",
            "\n",
            "[5 rows x 28 columns]\n",
            "\n",
            "▶ Verifying Python scripts:\n",
            "\n",
            "✓ src/python/data_collection.py\n",
            "✓ src/python/preprocessing.py\n",
            "✓ src/python/feature_engineering.py\n",
            "✓ src/python/modeling.py\n",
            "✓ src/python/main.py\n",
            "\n",
            "✓ All scripts found!\n",
            "\n",
            "✓ CELL 3 COMPLETE\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import traceback\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Set environment variable for correct data path\n",
        "os.environ['CSV_PATH'] = 'data/processed/nfl_panel_for_python.csv'\n",
        "\n",
        "# Configuration\n",
        "PYTHON_SCRIPTS = [\n",
        "    (\"src/python/data_collection.py\", \"Data Collection & Validation\"),\n",
        "    (\"src/python/preprocessing.py\", \"Data Preprocessing & Standardization\"),\n",
        "    (\"src/python/feature_engineering.py\", \"Feature Engineering\"),\n",
        "    (\"src/python/modeling.py\", \"Predictive Modeling & Analysis\")\n",
        "]\n",
        "\n",
        "LOG_FILE = Path(\"outputs\") / \"pipeline_execution.log\"\n",
        "SUMMARY_FILE = Path(\"outputs\") / \"pipeline_summary.json\"\n",
        "\n",
        "Path(\"outputs\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"CELL 4: RUNNING COMPLETE PIPELINE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Verify data exists\n",
        "csv_path = Path(\"data/processed/nfl_panel_for_python.csv\")\n",
        "if csv_path.exists():\n",
        "    print(f\"\\n✓ Data found: {csv_path}\")\n",
        "else:\n",
        "    print(f\"\\n✗ Data not found: {csv_path}\")\n",
        "    print(\"Make sure the CSV file is in the correct location!\")\n",
        "\n",
        "def run_script(script_name, description, idx, total):\n",
        "    \"\"\"Run a single Python script.\"\"\"\n",
        "    script_path = Path(script_name)\n",
        "\n",
        "    print(f\"\\n{'=' * 80}\")\n",
        "    print(f\"SCRIPT {idx}/{total}: {description}\")\n",
        "    print(f\"{'=' * 80}\\n\")\n",
        "\n",
        "    if not script_path.exists():\n",
        "        print(f\"✗ Script not found: {script_path}\")\n",
        "        return False, 0\n",
        "\n",
        "    start_time = datetime.now()\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [sys.executable, str(script_path)],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=3600\n",
        "        )\n",
        "\n",
        "        elapsed = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "        # Print output\n",
        "        if result.stdout:\n",
        "            print(result.stdout)\n",
        "\n",
        "        if result.stderr:\n",
        "            print(f\"STDERR:\\n{result.stderr}\")\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"\\n✓ {description} completed in {elapsed:.2f}s\")\n",
        "            return True, elapsed\n",
        "        else:\n",
        "            print(f\"\\n✗ {description} failed with return code {result.returncode}\")\n",
        "            return False, elapsed\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"✗ {description} timed out after 1 hour\")\n",
        "        return False, 3600\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error: {str(e)}\")\n",
        "        return False, 0\n",
        "\n",
        "# Execute scripts\n",
        "results = []\n",
        "execution_times = {}\n",
        "\n",
        "for idx, (script_name, description) in enumerate(PYTHON_SCRIPTS, 1):\n",
        "    success, elapsed = run_script(script_name, description, idx, len(PYTHON_SCRIPTS))\n",
        "    results.append((script_name, success, description))\n",
        "    execution_times[script_name] = elapsed\n",
        "\n",
        "    if not success:\n",
        "        print(f\"\\nStopping pipeline due to {script_name} failure\")\n",
        "        break\n",
        "\n",
        "# Calculate total time\n",
        "total_time = sum(execution_times.values())\n",
        "\n",
        "# Print summary\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PIPELINE EXECUTION SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "successful = [r for r in results if r[1]]\n",
        "failed = [r for r in results if not r[1]]\n",
        "\n",
        "print(f\"\\n✓ Successful: {len(successful)}/{len(results)}\")\n",
        "for script_name, success, description in successful:\n",
        "    elapsed = execution_times.get(script_name, 0)\n",
        "    print(f\"  • {description} ({elapsed:.2f}s)\")\n",
        "\n",
        "if failed:\n",
        "    print(f\"\\n✗ Failed: {len(failed)}/{len(results)}\")\n",
        "    for script_name, success, description in failed:\n",
        "        print(f\"  ✗ {description}\")\n",
        "\n",
        "print(f\"\\nTotal Pipeline Time: {total_time:.2f}s ({total_time/60:.2f} minutes)\")\n",
        "\n",
        "all_successful = all(r[1] for r in results)\n",
        "\n",
        "if all_successful:\n",
        "    print(\"\\n✓ PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "else:\n",
        "    print(\"\\n✗ PIPELINE COMPLETED WITH FAILURES\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"\\n✓ CELL 4 COMPLETE\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9wbX3nTeuMH",
        "outputId": "22346f38-d2f6-446f-b9ae-fdc6842be41c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CELL 4: RUNNING COMPLETE PIPELINE\n",
            "================================================================================\n",
            "\n",
            "✓ Data found: data/processed/nfl_panel_for_python.csv\n",
            "\n",
            "================================================================================\n",
            "SCRIPT 1/4: Data Collection & Validation\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "PYTHON DATA LOADING AND VALIDATION PIPELINE\n",
            "================================================================================\n",
            "\n",
            "1. Loading nfl_panel_for_python.csv...\n",
            "   ✓ Successfully loaded: 599 rows × 28 columns\n",
            "\n",
            "2. Inspecting data structure...\n",
            "\n",
            "   Column names and types:\n",
            "     • gsis_id: object\n",
            "     • season: int64\n",
            "     • metric_raw: float64\n",
            "     • volume: int64\n",
            "     • success_rate: float64\n",
            "     • total_epa: float64\n",
            "     • team: object\n",
            "     • position_group: object\n",
            "     • metric_secondary: float64\n",
            "     • mean_season: float64\n",
            "     • sd_season: float64\n",
            "     • z_score: float64\n",
            "     • years_exp: int64\n",
            "     • age: float64\n",
            "     • prev_team: object\n",
            "     • changed_team: int64\n",
            "     • years_since_change: int64\n",
            "     • transition_season: int64\n",
            "     • new_team: object\n",
            "     • rel_time: int64\n",
            "     • post_transition: int64\n",
            "     • phase: object\n",
            "     • team_pos_avg: float64\n",
            "     • team_quality: float64\n",
            "     • team_pass_epa_per_play: float64\n",
            "     • team_rush_epa_per_play: float64\n",
            "     • team_sack_rate: float64\n",
            "     • pre_trend_slope: float64\n",
            "\n",
            "   Data shape: (599, 28)\n",
            "\n",
            "   First 5 rows:\n",
            "      gsis_id  season  ...  team_sack_rate  pre_trend_slope\n",
            "0  00-0019596    2019  ...        0.043077              0.0\n",
            "1  00-0019596    2021  ...        0.030464              0.0\n",
            "2  00-0019596    2022  ...        0.028241              0.0\n",
            "3  00-0021206    2015  ...        0.079580              0.0\n",
            "4  00-0021206    2017  ...        0.084079              0.0\n",
            "\n",
            "[5 rows x 28 columns]\n",
            "\n",
            "3. Running data quality checks...\n",
            "   ✓ Total rows: 599\n",
            "   ✓ Total columns: 28\n",
            "   ✓ Memory usage (MB): 0.28\n",
            "   ✓ Duplicate rows: 0\n",
            "   ✓ Rows with any nulls: 599\n",
            "\n",
            "   Missing value analysis:\n",
            "     • metric_secondary: 517 (86.3%)\n",
            "     • total_epa: 455 (76.0%)\n",
            "     • success_rate: 82 (13.7%)\n",
            "     • prev_team: 58 (9.7%)\n",
            "     • pre_trend_slope: 58 (9.7%)\n",
            "\n",
            "4. Descriptive statistics...\n",
            "\n",
            "   Numeric columns summary:\n",
            "            season  metric_raw  ...  team_sack_rate  pre_trend_slope\n",
            "count   599.000000  599.000000  ...      599.000000       541.000000\n",
            "mean   2019.652755    5.651988  ...        0.065827        -0.131518\n",
            "std       2.850152    2.912534  ...        0.019415         0.743807\n",
            "min    2015.000000   -0.246165  ...        0.026168        -2.958404\n",
            "25%    2017.000000    4.061668  ...        0.053467         0.000000\n",
            "50%    2019.000000    6.111111  ...        0.063683         0.000000\n",
            "75%    2022.000000    7.726307  ...        0.079545         0.000000\n",
            "max    2024.000000   11.852632  ...        0.140264         1.679449\n",
            "\n",
            "[8 rows x 22 columns]\n",
            "\n",
            "   Categorical columns:\n",
            "     • gsis_id: 200 unique values\n",
            "     • team: 32 unique values\n",
            "     • position_group: 3 unique values\n",
            "     • prev_team: 32 unique values\n",
            "     • new_team: 31 unique values\n",
            "     • phase: 2 unique values\n",
            "\n",
            "5. Validating key variables...\n",
            "   Seasons: 2015 to 2024\n",
            "   Position groups:\n",
            "     • WR_TE: 373\n",
            "     • RB: 144\n",
            "     • QB: 82\n",
            "   Post-transition indicator:\n",
            "     • 1: 344\n",
            "     • 0: 255\n",
            "   Team changes:\n",
            "     • Changed (No): 355\n",
            "     • Changed (Yes): 244\n",
            "\n",
            "6. Creating derived metrics...\n",
            "   ✓ Created scaled metric\n",
            "   ✓ Created performance level categories\n",
            "   ✓ Created career phase categories\n",
            "   ✓ Created age polynomial features\n",
            "\n",
            "7. Creating player-season summaries...\n",
            "   ✓ Saved player-season summaries: 553 records\n",
            "\n",
            "8. Creating team-season summaries...\n",
            "   ✓ Saved team-season summaries: 257 records\n",
            "\n",
            "9. Analyzing transitions...\n",
            "   ✓ Identified 244 team transition events\n",
            "\n",
            "   Transition summary:\n",
            "     • Unique players: 200\n",
            "     • Positions affected:\n",
            "       - WR_TE: 138\n",
            "       - RB: 63\n",
            "       - QB: 43\n",
            "\n",
            "10. Saving enriched dataset...\n",
            "   ✓ Saved: nfl_panel_full.parquet\n",
            "   ✓ Saved: nfl_panel_full.csv\n",
            "\n",
            "11. Generating data quality report...\n",
            "   ✓ Saved: data_quality_report.json\n",
            "\n",
            "================================================================================\n",
            "DATA LOADING COMPLETE\n",
            "================================================================================\n",
            "\n",
            "Data summary:\n",
            "  • Records: 599\n",
            "  • Features: 32\n",
            "  • Seasons: 2015 to 2024\n",
            "\n",
            "Enriched data saved to: data/enriched/\n",
            "\n",
            "Files created:\n",
            "  ✓ nfl_panel_full.parquet\n",
            "  ✓ nfl_panel_full.csv\n",
            "  ✓ player_season_summary.parquet\n",
            "  ✓ team_season_summary.parquet\n",
            "  ✓ team_transitions.parquet\n",
            "  ✓ data_quality_report.json\n",
            "\n",
            "Next step: Run preprocessing.py\n",
            "================================================================================\n",
            "\n",
            "Data loading pipeline completed!\n",
            "\n",
            "\n",
            "✓ Data Collection & Validation completed in 0.72s\n",
            "\n",
            "================================================================================\n",
            "SCRIPT 2/4: Data Preprocessing & Standardization\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "DATA PREPROCESSING AND STANDARDIZATION\n",
            "================================================================================\n",
            "\n",
            "1. Loading enriched NFL data...\n",
            "   ✓ Loaded data: 599 rows × 32 columns\n",
            "\n",
            "2. Inspecting data structure...\n",
            "\n",
            "   Columns: ['gsis_id', 'season', 'metric_raw', 'volume', 'success_rate', 'total_epa', 'team', 'position_group', 'metric_secondary', 'mean_season', 'sd_season', 'z_score', 'years_exp', 'age', 'prev_team', 'changed_team', 'years_since_change', 'transition_season', 'new_team', 'rel_time', 'post_transition', 'phase', 'team_pos_avg', 'team_quality', 'team_pass_epa_per_play', 'team_rush_epa_per_play', 'team_sack_rate', 'pre_trend_slope', 'metric_raw_scaled', 'performance_level', 'career_phase', 'age_squared']\n",
            "\n",
            "   Data types:\n",
            "gsis_id                     object\n",
            "season                       int64\n",
            "metric_raw                 float64\n",
            "volume                       int64\n",
            "success_rate               float64\n",
            "total_epa                  float64\n",
            "team                        object\n",
            "position_group              object\n",
            "metric_secondary           float64\n",
            "mean_season                float64\n",
            "sd_season                  float64\n",
            "z_score                    float64\n",
            "years_exp                    int64\n",
            "age                        float64\n",
            "prev_team                   object\n",
            "changed_team                 int64\n",
            "years_since_change           int64\n",
            "transition_season            int64\n",
            "new_team                    object\n",
            "rel_time                     int64\n",
            "post_transition              int64\n",
            "phase                       object\n",
            "team_pos_avg               float64\n",
            "team_quality               float64\n",
            "team_pass_epa_per_play     float64\n",
            "team_rush_epa_per_play     float64\n",
            "team_sack_rate             float64\n",
            "pre_trend_slope            float64\n",
            "metric_raw_scaled          float64\n",
            "performance_level         category\n",
            "career_phase              category\n",
            "age_squared                float64\n",
            "dtype: object\n",
            "\n",
            "3. Cleaning and handling missing values...\n",
            "   Columns with missing values: 5\n",
            "          column  missing_count  missing_pct\n",
            "metric_secondary            517        86.31\n",
            "       total_epa            455        75.96\n",
            "    success_rate             82        13.69\n",
            "       prev_team             58         9.68\n",
            " pre_trend_slope             58         9.68\n",
            "   ✓ Missing values handled\n",
            "\n",
            "4. Checking for duplicates...\n",
            "   Duplicate rows found: 0\n",
            "\n",
            "5. Detecting and handling outliers...\n",
            "   Found and capped outliers in 5 columns\n",
            "     • pre_trend_slope: 251 outliers\n",
            "     • volume: 24 outliers\n",
            "     • years_exp: 5 outliers\n",
            "     • age_squared: 5 outliers\n",
            "     • age: 4 outliers\n",
            "\n",
            "6. Standardizing numeric features...\n",
            "   ✓ Standardized 18 numeric features\n",
            "\n",
            "7. Creating derived features...\n",
            "   ✓ Created 4 derived features\n",
            "\n",
            "8. Encoding categorical variables...\n",
            "   Encoded 2 categorical features\n",
            "\n",
            "9. Running data quality checks...\n",
            "   ✓ Total rows: 599\n",
            "   ✓ Total columns: 39\n",
            "   ✓ Duplicate rows: 0\n",
            "   ✓ Complete cases: 275\n",
            "   ✓ Completeness %: 98.61%\n",
            "\n",
            "   Data type distribution:\n",
            "     • float64: 19 columns\n",
            "     • object: 7 columns\n",
            "     • int64: 6 columns\n",
            "     • bool: 3 columns\n",
            "     • category: 1 columns\n",
            "     • category: 1 columns\n",
            "     • category: 1 columns\n",
            "     • category: 1 columns\n",
            "\n",
            "10. Creating train/validation/test splits...\n",
            "   Train: 0 obs (before transition-2)\n",
            "   Validation: 467 obs (transition-2 to transition)\n",
            "   Test: 132 obs (post-transition)\n",
            "\n",
            "11. Saving processed data...\n",
            "   ✓ Saved: nfl_panel_processed.csv/parquet\n",
            "   ✓ Saved split datasets (train/val/test)\n",
            "   ✓ Saved: preprocessing_metadata.json\n",
            "\n",
            "12. Generating preprocessing report...\n",
            "\n",
            "DATA PREPROCESSING REPORT\n",
            "================================================================================\n",
            "\n",
            "DATASET OVERVIEW:\n",
            "- Total observations: 599\n",
            "- Total features: 40\n",
            "- Date: 2026-01-05 05:31:04\n",
            "\n",
            "DATA QUALITY:\n",
            "- Completeness: 98.61%\n",
            "- Duplicate rows: 0\n",
            "- Complete cases: 275\n",
            "\n",
            "TRANSFORMATIONS APPLIED:\n",
            "1. Missing value handling: 5 columns filled\n",
            "2. Outlier detection: 5 columns capped\n",
            "3. Standardization: 18 numeric features scaled\n",
            "4. Feature engineering: 2 categorical features encoded\n",
            "5. Derived features: 4 new features created\n",
            "\n",
            "DATA TYPE DISTRIBUTION:\n",
            "float64     19\n",
            "object       7\n",
            "int64        6\n",
            "bool         3\n",
            "category     1\n",
            "category     1\n",
            "category     1\n",
            "category     1\n",
            "\n",
            "READY FOR FEATURE ENGINEERING AND MODELING\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "DATA PREPROCESSING COMPLETE\n",
            "================================================================================\n",
            "\n",
            "Processed data saved to: data/processed/\n",
            "\n",
            "Files created:\n",
            "  • nfl_panel_processed.csv/parquet\n",
            "  • train_dataset.csv\n",
            "  • validation_dataset.csv\n",
            "  • test_dataset.csv\n",
            "  • preprocessing_metadata.json\n",
            "  • preprocessing_report.txt\n",
            "\n",
            "Next step: Run feature_engineering.py\n",
            "================================================================================\n",
            "\n",
            "Preprocessing pipeline completed successfully!\n",
            "\n",
            "\n",
            "✓ Data Preprocessing & Standardization completed in 1.44s\n",
            "\n",
            "================================================================================\n",
            "SCRIPT 3/4: Feature Engineering\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MACHINE LEARNING FEATURE ENGINEERING\n",
            "================================================================================\n",
            "\n",
            "Loaded 599 observations from preprocessing\n",
            "\n",
            "1. Engineering career trajectory features...\n",
            "   ✓ Created polynomial and exponential age features\n",
            "\n",
            "2. Creating rolling window features...\n",
            "   ✓ Created rolling window features\n",
            "\n",
            "3. Creating momentum indicators...\n",
            "   ✓ Created momentum and acceleration features\n",
            "\n",
            "4. Creating interaction features...\n",
            "   ✓ Created interaction features\n",
            "\n",
            "5. Applying PCA for dimensionality reduction...\n",
            "   ✓ Created 10 principal components\n",
            "\n",
            "6. Assembling master feature set...\n",
            "   Master feature set: 599 rows × 40 columns\n",
            "\n",
            "7. Creating train/test split...\n",
            "   ⚠ No training data from split. Combining validation + test (60/40 split)...\n",
            "   Train: 255 obs\n",
            "   Test:  344 obs\n",
            "\n",
            "   Final split:\n",
            "   Train: 255 obs\n",
            "   Test:  344 obs\n",
            "\n",
            "8. Generating feature metadata...\n",
            "\n",
            "================================================================================\n",
            "FEATURE ENGINEERING COMPLETE\n",
            "================================================================================\n",
            "\n",
            "All features saved to: data/ml_features\n",
            "\n",
            "Ready for predictive modeling (modeling.py)\n",
            "================================================================================\n",
            "\n",
            "\n",
            "\n",
            "✓ Feature Engineering completed in 1.61s\n",
            "\n",
            "================================================================================\n",
            "SCRIPT 4/4: Predictive Modeling & Analysis\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "PREDICTIVE MODELING - SECONDARY RESEARCH QUESTION\n",
            "================================================================================\n",
            "\n",
            "Secondary Research Question:\n",
            "Using only pre-transition player and team characteristics, can we predict\n",
            "the magnitude and direction of post-transition performance change with\n",
            "sufficient out-of-sample accuracy (R²) to inform practical personnel decisions,\n",
            "and which pre-transition features (e.g., age deviation from position-specific\n",
            "peak, recent momentum/acceleration, pre-trend slope) are most predictive\n",
            "of success or failure?\n",
            "\n",
            "================================================================================\n",
            "\n",
            "1. Loading feature-engineered data...\n",
            " ✓ Loaded: 599 observations\n",
            "\n",
            "2. Creating target variable: performance_change (z-score diff)...\n",
            "   Mean change: -0.1274\n",
            "   Std change : 1.3144\n",
            "   Post-transition records: 244\n",
            "\n",
            "3. Defining pre-transition features...\n",
            "   Available features (16):\n",
            "     • metric_raw\n",
            "     • volume\n",
            "     • success_rate\n",
            "     • total_epa\n",
            "     • metric_secondary\n",
            "     • mean_season\n",
            "     • sd_season\n",
            "     • years_exp\n",
            "     • age\n",
            "     • age_squared\n",
            "     • team_pos_avg\n",
            "     • team_quality\n",
            "     • team_pass_epa_per_play\n",
            "     • team_rush_epa_per_play\n",
            "     • team_sack_rate\n",
            "     • pre_trend_slope\n",
            "\n",
            "4. Preparing modeling dataset...\n",
            "   Train: 144 | Test: 62\n",
            "\n",
            "5. Training global Gradient Boosting Regressor...\n",
            "   R² : 0.3029\n",
            "   RMSE: 1.0373\n",
            "   MAE : 0.8357\n",
            "\n",
            "6. Global feature importance (all positions combined)...\n",
            "\n",
            "Top global predictors of post-transition performance change:\n",
            "               feature  importance\n",
            "          team_pos_avg    0.220525\n",
            "            metric_raw    0.206887\n",
            "                volume    0.079278\n",
            "          success_rate    0.073504\n",
            "        team_sack_rate    0.063707\n",
            "             total_epa    0.062136\n",
            "team_rush_epa_per_play    0.055641\n",
            "           mean_season    0.047178\n",
            "                   age    0.041837\n",
            "team_pass_epa_per_play    0.041565\n",
            "          team_quality    0.034258\n",
            "           age_squared    0.026439\n",
            "             years_exp    0.016685\n",
            "      metric_secondary    0.015585\n",
            "             sd_season    0.014774\n",
            "       pre_trend_slope    0.000000\n",
            "\n",
            "7. Generating detailed prediction results...\n",
            "   Direction predicted correctly: 72.6%\n",
            "   Mean absolute error: 0.8357 z-score units\n",
            "   Saved detailed predictions to predictions_secondary.csv\n",
            "\n",
            "8. Position-specific feature importance analysis...\n",
            "   No position column found. Skipping position-specific analysis.\n",
            "\n",
            "9. Creating key visualizations...\n",
            "   Saved actual_vs_predicted_secondary.png\n",
            "\n",
            "================================================================================\n",
            "SECONDARY RESEARCH QUESTION SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Out-of-sample predictive accuracy:\n",
            "   • R² = 0.3029 (MODERATE explanatory power)\n",
            "   • Direction correct in 72.6% of cases\n",
            "   • Practical utility for personnel decisions: YES – sufficient signal to inform practical personnel decisions\n",
            "\n",
            "Top global pre-transition predictors of success/failure:\n",
            "   1. team_pos_avg                   0.2205\n",
            "   2. metric_raw                     0.2069\n",
            "   3. volume                         0.0793\n",
            "   4. success_rate                   0.0735\n",
            "   5. team_sack_rate                 0.0637\n",
            "   6. total_epa                      0.0621\n",
            "   7. team_rush_epa_per_play         0.0556\n",
            "\n",
            "All results saved to outputs/analysis/ and outputs/figures/\n",
            "================================================================================\n",
            "ANALYSIS COMPLETE\n",
            "================================================================================\n",
            "\n",
            "\n",
            "✓ Predictive Modeling & Analysis completed in 3.95s\n",
            "\n",
            "================================================================================\n",
            "PIPELINE EXECUTION SUMMARY\n",
            "================================================================================\n",
            "\n",
            "✓ Successful: 4/4\n",
            "  • Data Collection & Validation (0.72s)\n",
            "  • Data Preprocessing & Standardization (1.44s)\n",
            "  • Feature Engineering (1.61s)\n",
            "  • Predictive Modeling & Analysis (3.95s)\n",
            "\n",
            "Total Pipeline Time: 7.72s (0.13 minutes)\n",
            "\n",
            "✓ PIPELINE COMPLETED SUCCESSFULLY!\n",
            "================================================================================\n",
            "\n",
            "✓ CELL 4 COMPLETE\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"CELL 5: DISPLAYING RESULTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "results_dir = Path(\"outputs/analysis\")\n",
        "\n",
        "# Check what files were created\n",
        "print(\"\\n▶ Output files created:\\n\")\n",
        "\n",
        "if results_dir.exists():\n",
        "    for file in sorted(results_dir.glob(\"*.csv\")):\n",
        "        size = file.stat().st_size / 1024\n",
        "        print(f\"✓ {file.name} ({size:.1f} KB)\")\n",
        "else:\n",
        "    print(\"✗ No analysis directory found\")\n",
        "\n",
        "# Load and display model comparison\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "model_comp_path = results_dir / \"model_comparison.csv\"\n",
        "if model_comp_path.exists():\n",
        "    model_comparison = pd.read_csv(model_comp_path)\n",
        "    print(\"\\n\" + model_comparison.to_string(index=False))\n",
        "    print()\n",
        "else:\n",
        "    print(\"Model comparison file not found\")\n",
        "\n",
        "# Load and display feature importance\n",
        "print(\"=\" * 80)\n",
        "print(\"TOP 15 IMPORTANT FEATURES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "feature_imp_path = results_dir / \"feature_importance.csv\"\n",
        "if feature_imp_path.exists():\n",
        "    feature_importance = pd.read_csv(feature_imp_path)\n",
        "    print(\"\\n\" + feature_importance.head(15).to_string(index=False))\n",
        "    print()\n",
        "else:\n",
        "    print(\"Feature importance file not found\")\n",
        "\n",
        "# Display figures\n",
        "print(\"=\" * 80)\n",
        "print(\"VISUALIZATIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "figs_dir = Path(\"outputs/figures\")\n",
        "if figs_dir.exists():\n",
        "    figures = list(figs_dir.glob(\"*.png\"))\n",
        "    print(f\"\\n✓ {len(figures)} figures generated:\\n\")\n",
        "\n",
        "    for fig in sorted(figures):\n",
        "        print(f\"  • {fig.name}\")\n",
        "\n",
        "print(\"\\n✓ CELL 5 COMPLETE\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFgZdI-1exiu",
        "outputId": "25583fd7-73b8-41b7-b46f-a154189278cd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CELL 5: DISPLAYING RESULTS\n",
            "================================================================================\n",
            "\n",
            "▶ Output files created:\n",
            "\n",
            "✓ feature_importance.csv (0.4 KB)\n",
            "✓ feature_importance_global.csv (0.5 KB)\n",
            "✓ feature_importance_secondary.csv (0.5 KB)\n",
            "✓ model_comparison.csv (0.3 KB)\n",
            "✓ predictions.csv (26.6 KB)\n",
            "✓ predictions_research_question.csv (5.3 KB)\n",
            "✓ predictions_secondary.csv (23.0 KB)\n",
            "\n",
            "================================================================================\n",
            "MODEL COMPARISON\n",
            "================================================================================\n",
            "\n",
            "            Model       R2     RMSE      MAE\n",
            "          XGBoost 0.280444 1.053901 0.844994\n",
            "            Ridge 0.263358 1.066340 0.870440\n",
            "            Lasso 0.257215 1.070776 0.864993\n",
            "    Random Forest 0.256035 1.071627 0.869984\n",
            "Gradient Boosting 0.248362 1.077139 0.881580\n",
            "\n",
            "================================================================================\n",
            "TOP 15 IMPORTANT FEATURES\n",
            "================================================================================\n",
            "\n",
            "               feature  importance\n",
            "          team_pos_avg    0.293631\n",
            "             total_epa    0.128901\n",
            "                   age    0.101058\n",
            "team_pass_epa_per_play    0.092759\n",
            "          team_quality    0.060471\n",
            "            metric_raw    0.058338\n",
            "                volume    0.052367\n",
            "           mean_season    0.046496\n",
            "          success_rate    0.042894\n",
            "team_rush_epa_per_play    0.039984\n",
            "             years_exp    0.030332\n",
            "        team_sack_rate    0.027663\n",
            "      metric_secondary    0.012742\n",
            "             sd_season    0.012363\n",
            "           age_squared    0.000000\n",
            "\n",
            "================================================================================\n",
            "VISUALIZATIONS\n",
            "================================================================================\n",
            "\n",
            "✓ 9 figures generated:\n",
            "\n",
            "  • actual_vs_predicted.png\n",
            "  • actual_vs_predicted_change.png\n",
            "  • actual_vs_predicted_secondary.png\n",
            "  • error_analysis.png\n",
            "  • feature_importance.png\n",
            "  • feature_importance_global.png\n",
            "  • feature_importance_research_question.png\n",
            "  • feature_importance_secondary.png\n",
            "  • residual_plot.png\n",
            "\n",
            "✓ CELL 5 COMPLETE\n",
            "\n"
          ]
        }
      ]
    }
  ]
}